{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aunghlaingtun/NYP_ITI_105_MLPrj/blob/main/Linear_Model_Data_Preposs_ID_6319250G.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlf9M9r61C_-"
      },
      "source": [
        "# ITI-105 Machine Learning Project: HDB Resale Price Prediction\n",
        "## Linear Model Development with Comprehensive Analysis & MLflow Tracking\n",
        "\n",
        "**Student Information:**\n",
        "- **Name:** Aung Hlaing Tun\n",
        "- **Student ID:** 6319250G\n",
        "- **Project Group ID:** AlgroRiddler\n",
        "- **Date:** [ 29 Aug 2025]\n",
        "\n",
        "**Project Overview:**\n",
        "This notebook implements a comprehensive machine learning pipeline for HDB resale price prediction, featuring:\n",
        "- ‚úÖ Professional data preprocessing and feature engineering\n",
        "- ‚úÖ Comprehensive correlation analysis\n",
        "- ‚úÖ Multi-method outlier detection (IQR, Z-Score, Isolation Forest, Domain-specific)\n",
        "- ‚úÖ Linear regression models with hyperparameter tuning\n",
        "- ‚úÖ Complete MLflow experiment tracking (no warnings)\n",
        "- ‚úÖ Professional visualizations and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Shc3bCpMNVX"
      },
      "source": [
        "## 1. Environment Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab/Jupyter\n",
        "!pip uninstall -y mlflow\n",
        "!pip install \"mlflow<3\" dagshub\n",
        "# Restart the kernel if your environment doesn‚Äôt auto-reload:\n",
        "import os; os._exit(0)\n"
      ],
      "metadata": {
        "id": "d4HUkGL1Qv1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d013713a"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install mlflow pyngrok geopy scikit-learn -q\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "print(\"MLflow version:\", mlflow.__version__)  # should show 2.x.x\n"
      ],
      "metadata": {
        "id": "ubJA-QNVRlED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  2.Connect to your DagsHub repo (set token + tracking URI)"
      ],
      "metadata": {
        "id": "YmboRwYjR2fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, mlflow, dagshub\n",
        "from google.colab import userdata # Import userdata to access Colab secrets\n",
        "\n",
        "# ==== FILL THESE ====\n",
        "USER = \"aunghlaingtun\"        # your DagsHub username (or org)\n",
        "REPO = \"NYP_ITI_105\"          # your repo\n",
        "\n",
        "TOKEN = userdata.get('dagshub') # Get token from Colab secrets\n",
        "\n",
        "# Auth (do NOT hard-code token in public notebooks‚Äîuse env/secrets in real life)\n",
        "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = USER\n",
        "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = TOKEN\n",
        "\n",
        "# Point MLflow to your repo (dagshub.init also sets the tracking URI)\n",
        "dagshub.init(repo_owner=USER, repo_name=REPO, mlflow=True)\n",
        "\n",
        "# Create/use a consistent experiment name (you can make Step1/Step2/Step3 too)\n",
        "mlflow.set_experiment(\"HDB_Linear_Workflow\")\n",
        "\n",
        "print(\"Tracking URI ->\", mlflow.get_tracking_uri())\n",
        "print(\"Open experiments:\", f\"https://dagshub.com/{USER}/{REPO}.mlflow/#/experiments\")"
      ],
      "metadata": {
        "id": "eGboq2yRR0qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Smoke Test!**"
      ],
      "metadata": {
        "id": "FNCR05U91Twe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(run_name=\"smoke_test\"):\n",
        "    mlflow.log_params({\"model\":\"LinearRegression\", \"data_version\":\"HDB_2015_2025_v1\"})\n",
        "    mlflow.log_metrics({\"r2\":0.9691, \"rmse\":31419, \"mae\":20856, \"mape\":4.52})\n",
        "\n",
        "print(\"Now open:\", f\"https://dagshub.com/{USER}/{REPO}.mlflow/#/experiments\")\n"
      ],
      "metadata": {
        "id": "sW98Y-fKVGhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_imports"
      },
      "source": [
        "## 3. Import Libraries & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_cell"
      },
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Geospatial analysis\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Machine Learning\n",
        "import sklearn # Import sklearn directly to access __version__\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from scipy import stats\n",
        "\n",
        "# MLflow for experiment tracking\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "print(f\"ü§ñ Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"üìà MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlflow_setup"
      },
      "source": [
        "## 4. MLflow Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlflow_setup_cell"
      },
      "outputs": [],
      "source": [
        "# from pyngrok import ngrok # ngrok is not needed for DagsHub UI\n",
        "\n",
        "def setup_comprehensive_mlflow():\n",
        "    \"\"\"Setup comprehensive MLflow tracking with proper experiment organization\"\"\"\n",
        "    print(\"üöÄ COMPREHENSIVE MLFLOW SETUP\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Set tracking URI for DagsHub persistence (already set by dagshub.init)\n",
        "    # tracking_uri = \"file:///content/drive/MyDrive/26AUGRunlog2\" # Removed my local file tracking\n",
        "    # os.makedirs(\"/content/drive/MyDrive/26AUGRunlog2\", exist_ok=True) # Remove local directory creation\n",
        "    # mlflow.set_tracking_uri(tracking_uri) # Remove explicit setting if dagshub.init is used\n",
        "    print(f\"‚úì MLflow tracking URI: {mlflow.get_tracking_uri()}\") # Get URI from dagshub.init\n",
        "\n",
        "    # Create main experiment\n",
        "    experiment_name = \"HDB_Comprehensive_Analysis_Professional\"\n",
        "\n",
        "    try:\n",
        "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "        if experiment is None:\n",
        "            # artifact_location is not needed when tracking to DagsHub\n",
        "            experiment_id = mlflow.create_experiment(experiment_name)\n",
        "            print(f\"‚úì Created new experiment: {experiment_name}\")\n",
        "        else:\n",
        "            experiment_id = experiment.experiment_id\n",
        "            print(f\"‚úì Using existing experiment: {experiment_name}\")\n",
        "\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        return experiment_id\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error setting up MLflow: {e}\")\n",
        "        return None\n",
        "\n",
        "# def start_mlflow_ui(): # Remove ngrok UI function\n",
        "#     \"\"\"Start MLflow UI with ngrok tunnel\"\"\"\n",
        "#     print(\"\\nüåê STARTING MLFLOW UI\")\n",
        "#     print(\"=\" * 40)\n",
        "\n",
        "#     # Kill existing ngrok processes\n",
        "#     try:\n",
        "#         ngrok.kill()\n",
        "#         print(\"‚úì Killed existing ngrok processes\")\n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "#     # Start MLflow UI in background\n",
        "#     mlflow_process = subprocess.Popen(\n",
        "#         [\"mlflow\", \"ui\", \"--backend-store-uri\", \"file:///content/drive/MyDrive/26AUGRunlog2\",\n",
        "#          \"--port\", \"5000\", \"--host\", \"0.0.0.0\"],\n",
        "#         stdout=subprocess.PIPE,\n",
        "#         stderr=subprocess.PIPE\n",
        "#     )\n",
        "\n",
        "#     # Wait for MLflow to start\n",
        "#     time.sleep(5)\n",
        "\n",
        "#     # Create ngrok tunnel\n",
        "#     try:\n",
        "#         public_url = ngrok.connect(5000)\n",
        "#         print(f\"üöÄ MLflow UI is live at: {public_url}\")\n",
        "#         print(\"üìä Access your experiment tracking dashboard!\")\n",
        "#         return str(public_url)\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Failed to create ngrok tunnel: {e}\")\n",
        "#         return None\n",
        "\n",
        "# Setup MLflow\n",
        "experiment_id = setup_comprehensive_mlflow()\n",
        "# mlflow_url = start_mlflow_ui() # i Removed that for  ngrok UI start\n",
        "\n",
        "if experiment_id:\n",
        "    print(f\"\\n‚úÖ MLflow setup complete!\")\n",
        "    print(f\"üìä Experiment ID: {experiment_id}\")\n",
        "    # if mlflow_url: # Remove ngrok UI URL print\n",
        "        # print(f\"üåê MLflow UI: {mlflow_url}\")\n",
        "\n",
        "print(f\"üåê Access MLflow UI on DagsHub: https://dagshub.com/{USER}/{REPO}.mlflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading"
      },
      "source": [
        "## 5. Data Loading & Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_upload_cell"
      },
      "outputs": [],
      "source": [
        "# Upload my data of 4 CSV files\n",
        "print(\"üìÅ Please upload  4 CSV files:\")\n",
        "print(\"1. base_hdb_resale_prices_2015Jan-2025Jun.csv\")\n",
        "print(\"2. clean_hdb_coordinates.csv\")\n",
        "print(\"3. CPI_2015Jan-2025Jun.csv\")\n",
        "print(\"4. clean_mrt_lrt_coordinates_2025Jan.csv\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(f\"\\n‚úÖ Uploaded {len(uploaded)} files successfully!\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"   üìÑ {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_loading_cell",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def load_datasets_professional():\n",
        "    \"\"\"Load all 4 CSV datasets with comprehensive validation\"\"\"\n",
        "    print(\"\\nüìä LOADING HDB DATASETS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Define expected files\n",
        "    expected_files = {\n",
        "        'hdb_prices': 'base_hdb_resale_prices_2015Jan_2025Jun.csv',\n",
        "        'hdb_coords': 'clean_hdb_coordinates.csv',\n",
        "        'cpi_data': 'CPI_2015Jan-2025Jun.csv',\n",
        "        'mrt_coords': 'clean_mrt_lrt_coordinates_2025Jan.csv'\n",
        "    }\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    for key, filename in expected_files.items():\n",
        "        try:\n",
        "            print(f\"Loading {filename}...\")\n",
        "            df = pd.read_csv(filename)\n",
        "            datasets[key] = df\n",
        "            print(f\"‚úì {key}: {df.shape[0]:,} records, {df.shape[1]} columns\")\n",
        "\n",
        "            # Basic validation\n",
        "            missing_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n",
        "            print(f\"  Missing data: {missing_pct:.2f}%\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ùå File not found: {filename}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading {filename}: {e}\")\n",
        "            return None\n",
        "\n",
        "    print(\"\\n‚úÖ All datasets loaded successfully!\")\n",
        "    return datasets\n",
        "\n",
        "# Load datasets\n",
        "datasets = load_datasets_professional()\n",
        "\n",
        "if datasets:\n",
        "    hdb_prices = datasets['hdb_prices']\n",
        "    hdb_coords = datasets['hdb_coords']\n",
        "    cpi_data = datasets['cpi_data']\n",
        "    mrt_coords = datasets['mrt_coords']\n",
        "\n",
        "    print(f\"\\nüìà Dataset Summary:\")\n",
        "    print(f\"   Total HDB transactions: {len(hdb_prices):,}\")\n",
        "    print(f\"   HDB locations: {len(hdb_coords):,}\")\n",
        "    print(f\"   CPI data points: {len(cpi_data):,}\")\n",
        "    print(f\"   MRT/LRT stations: {len(mrt_coords):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display data info for each dataframe\n",
        "print(\"--- hdb_prices Info ---\")\n",
        "hdb_prices.info()\n",
        "print(\"\\n--- hdb_coords Info ---\")\n",
        "hdb_coords.info()\n",
        "print(\"\\n--- cpi_data Info ---\")\n",
        "cpi_data.info()\n",
        "print(\"\\n--- mrt_coords Info ---\")\n",
        "mrt_coords.info()"
      ],
      "metadata": {
        "id": "Jz7O-xzlkAtc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_preprocessing"
      },
      "source": [
        "## 6. Data Preprocessing & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing_cell"
      },
      "outputs": [],
      "source": [
        "def comprehensive_data_preprocessing(hdb_prices, hdb_coords, cpi_data, mrt_coords):\n",
        "    \"\"\"Comprehensive data preprocessing with feature engineering\"\"\"\n",
        "    print(\"\\nüîß COMPREHENSIVE DATA PREPROCESSING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Clean HDB prices data\n",
        "    print(\"1. Processing HDB resale prices...\")\n",
        "    hdb_clean = hdb_prices.copy()\n",
        "\n",
        "    # Convert date column\n",
        "    hdb_clean['month'] = pd.to_datetime(hdb_clean['month'])\n",
        "\n",
        "    # Extract remaining lease years\n",
        "    def extract_remaining_years(lease_str):\n",
        "        if pd.isna(lease_str):\n",
        "            return np.nan\n",
        "        if isinstance(lease_str, (int, float)):\n",
        "            return float(lease_str)\n",
        "\n",
        "        years = 0\n",
        "        months = 0\n",
        "        year_match = re.search(r'(\\d+)\\s*years?', str(lease_str))\n",
        "        month_match = re.search(r'(\\d+)\\s*months?', str(lease_str))\n",
        "\n",
        "        if year_match:\n",
        "            years = int(year_match.group(1))\n",
        "        if month_match:\n",
        "            months = int(month_match.group(1))\n",
        "\n",
        "        return years + months/12\n",
        "\n",
        "    hdb_clean['remaining_lease_years'] = hdb_clean['remaining_lease'].apply(extract_remaining_years)\n",
        "\n",
        "    # Extract storey information\n",
        "    def extract_storey_info(storey_range):\n",
        "        if pd.isna(storey_range):\n",
        "            return np.nan, np.nan, np.nan\n",
        "\n",
        "        parts = str(storey_range).split(' TO ')\n",
        "        if len(parts) == 2:\n",
        "            min_storey = int(parts[0])\n",
        "            max_storey = int(parts[1])\n",
        "            mid_storey = (min_storey + max_storey) / 2\n",
        "            return min_storey, max_storey, mid_storey\n",
        "        return np.nan, np.nan, np.nan\n",
        "\n",
        "    storey_info = hdb_clean['storey_range'].apply(extract_storey_info)\n",
        "    hdb_clean['min_storey'] = [x[0] for x in storey_info]\n",
        "    hdb_clean['max_storey'] = [x[1] for x in storey_info]\n",
        "    hdb_clean['mid_storey'] = [x[2] for x in storey_info]\n",
        "\n",
        "    # Create property age\n",
        "    current_year = datetime.now().year\n",
        "    hdb_clean['property_age'] = current_year - hdb_clean['lease_commence_date']\n",
        "\n",
        "    # Create address matching key\n",
        "    hdb_clean['full_address'] = (hdb_clean['block'] + ' ' + hdb_clean['street_name']).str.lower()\n",
        "\n",
        "    print(f\"   ‚úì Processed {len(hdb_clean):,} HDB records\")\n",
        "\n",
        "    # 2. Process CPI data\n",
        "    print(\"2. Processing CPI data...\")\n",
        "    cpi_clean = cpi_data.copy()\n",
        "    cpi_clean['month_clean'] = cpi_clean['month'].str.replace(' ', '-')\n",
        "    cpi_clean['month_date'] = pd.to_datetime(cpi_clean['month_clean'], format='%Y-%b')\n",
        "    print(f\"   ‚úì Processed {len(cpi_clean):,} CPI records\")\n",
        "\n",
        "    # 3. Merge datasets\n",
        "    print(\"3. Merging all datasets...\")\n",
        "\n",
        "    # Merge with coordinates\n",
        "    hdb_coords['full_address'] = hdb_coords['full_address'].str.lower()\n",
        "    merged_data = hdb_clean.merge(hdb_coords, on='full_address', how='left')\n",
        "    print(f\"   ‚úì Merged coordinates: {merged_data['longitude'].notna().sum():,} records\")\n",
        "\n",
        "    # Merge with CPI\n",
        "    merged_data['year_month'] = merged_data['month'].dt.to_period('M')\n",
        "    cpi_clean['year_month'] = cpi_clean['month_date'].dt.to_period('M')\n",
        "    merged_data = merged_data.merge(cpi_clean[['year_month', 'cpi']], on='year_month', how='left')\n",
        "    print(f\"   ‚úì Merged CPI: {merged_data['cpi'].notna().sum():,} records\")\n",
        "\n",
        "    # 4. Calculate MRT distances (simplified by town)\n",
        "    print(\"4. Calculating MRT distances...\")\n",
        "\n",
        "    def calculate_min_distance_to_mrt(row, mrt_coords):\n",
        "        if pd.isna(row['longitude']) or pd.isna(row['latitude']):\n",
        "            return np.nan\n",
        "\n",
        "        hdb_location = (row['latitude'], row['longitude'])\n",
        "        min_distance = float('inf')\n",
        "\n",
        "        for _, mrt in mrt_coords.iterrows():\n",
        "            mrt_location = (mrt['latitude'], mrt['longitude'])\n",
        "            distance = geodesic(hdb_location, mrt_location).kilometers\n",
        "            min_distance = min(min_distance, distance)\n",
        "\n",
        "        return min_distance\n",
        "\n",
        "    # Calculate average distance for each town (for performance)\n",
        "    town_mrt_distances = {}\n",
        "    for town in merged_data['town'].unique():\n",
        "        town_data = merged_data[merged_data['town'] == town]\n",
        "        if len(town_data) > 0:\n",
        "            town_record = town_data.dropna(subset=['longitude', 'latitude']).iloc[0:1]\n",
        "            if len(town_record) > 0:\n",
        "                distance = calculate_min_distance_to_mrt(town_record.iloc[0], mrt_coords)\n",
        "                town_mrt_distances[town] = distance\n",
        "\n",
        "    merged_data['distance_to_mrt'] = merged_data['town'].map(town_mrt_distances)\n",
        "    print(f\"   ‚úì Calculated MRT distances: {merged_data['distance_to_mrt'].notna().sum():,} records\")\n",
        "\n",
        "    # 5. Feature engineering\n",
        "    print(\"5. Creating additional features...\")\n",
        "\n",
        "    # Price per square meter\n",
        "    merged_data['price_per_sqm'] = merged_data['resale_price'] / merged_data['floor_area_sqm']\n",
        "\n",
        "    # Time-based features\n",
        "    merged_data['year'] = merged_data['month'].dt.year\n",
        "    merged_data['month_num'] = merged_data['month'].dt.month\n",
        "    merged_data['quarter'] = merged_data['month'].dt.quarter\n",
        "\n",
        "    # Price categories\n",
        "    merged_data['price_category'] = pd.cut(\n",
        "        merged_data['resale_price'],\n",
        "        bins=[0, 400000, 600000, 800000, float('inf')],\n",
        "        labels=['Low', 'Medium', 'High', 'Premium']\n",
        "    )\n",
        "\n",
        "    print(f\"   ‚úì Created additional features\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Preprocessing complete!\")\n",
        "    print(f\"üìä Final dataset: {len(merged_data):,} records, {merged_data.shape[1]} columns\")\n",
        "\n",
        "    return merged_data\n",
        "\n",
        "# Run comprehensive preprocessing\n",
        "if datasets:\n",
        "    final_data = comprehensive_data_preprocessing(hdb_prices, hdb_coords, cpi_data, mrt_coords)\n",
        "\n",
        "    # Display basic statistics\n",
        "    print(f\"\\nüìà Price Statistics:\")\n",
        "    print(f\"   Mean: ${final_data['resale_price'].mean():,.0f}\")\n",
        "    print(f\"   Median: ${final_data['resale_price'].median():,.0f}\")\n",
        "    print(f\"   Range: ${final_data['resale_price'].min():,.0f} - ${final_data['resale_price'].max():,.0f}\")\n",
        "    print(f\"   Standard Deviation: ${final_data['resale_price'].std():,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "correlation_analysis"
      },
      "source": [
        "## 7. Comprehensive Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "correlation_cell"
      },
      "outputs": [],
      "source": [
        "def comprehensive_correlation_analysis(data, experiment_id):\n",
        "    \"\"\"Comprehensive correlation analysis with MLflow logging\"\"\"\n",
        "    print(\"\\nüîç COMPREHENSIVE CORRELATION ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"Correlation_Analysis_Professional\") as run:\n",
        "        # Select numerical columns for correlation\n",
        "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Remove target-related columns to avoid data leakage\n",
        "        target_related = ['resale_price']\n",
        "        feature_cols = [col for col in numerical_cols if col not in target_related]\n",
        "\n",
        "        if 'resale_price' in numerical_cols:\n",
        "            # Calculate correlations with target\n",
        "            target_correlations = data[feature_cols + ['resale_price']].corr()['resale_price'].drop('resale_price')\n",
        "            target_correlations = target_correlations.sort_values(key=abs, ascending=False)\n",
        "\n",
        "            # Log top correlations to MLflow\n",
        "            mlflow.log_metric(\"highest_positive_correlation\", target_correlations.max())\n",
        "            mlflow.log_metric(\"highest_negative_correlation\", target_correlations.min())\n",
        "            mlflow.log_metric(\"mean_absolute_correlation\", target_correlations.abs().mean())\n",
        "\n",
        "            print(f\"üìä Correlation Analysis Results:\")\n",
        "            print(f\"   Highest positive correlation: {target_correlations.max():.4f} ({target_correlations.idxmax()})\")\n",
        "            print(f\"   Highest negative correlation: {target_correlations.min():.4f} ({target_correlations.idxmin()})\")\n",
        "            print(f\"   Mean absolute correlation: {target_correlations.abs().mean():.4f}\")\n",
        "\n",
        "            # Create correlation with target plot\n",
        "            plt.figure(figsize=(14, 10))\n",
        "            top_corr = target_correlations.head(15)\n",
        "            colors = ['red' if corr < 0 else 'blue' for corr in top_corr.values]\n",
        "            bars = plt.barh(range(len(top_corr)), top_corr.values, color=colors, alpha=0.8)\n",
        "            plt.yticks(range(len(top_corr)), top_corr.index)\n",
        "            plt.xlabel('Correlation with Resale Price', fontsize=12)\n",
        "            plt.title('Top 15 Feature Correlations with HDB Resale Price', fontsize=14, fontweight='bold')\n",
        "            plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "            plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, bar in enumerate(bars):\n",
        "                width = bar.get_width()\n",
        "                plt.text(width + (0.01 if width > 0 else -0.01), bar.get_y() + bar.get_height()/2,\n",
        "                        f'{width:.3f}', ha='left' if width > 0 else 'right', va='center', fontsize=10)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"target_correlations.png\", dpi=300, bbox_inches='tight')\n",
        "            mlflow.log_artifact(\"target_correlations.png\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            # Save correlation data\n",
        "            target_correlations.to_csv(\"target_correlations.csv\")\n",
        "            mlflow.log_artifact(\"target_correlations.csv\")\n",
        "\n",
        "        # Full correlation matrix\n",
        "        correlation_matrix = data[feature_cols].corr()\n",
        "\n",
        "        # Create correlation heatmap\n",
        "        plt.figure(figsize=(16, 12))\n",
        "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "        sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm',\n",
        "                   center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "        plt.title('Feature Correlation Matrix (Lower Triangle)', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "        mlflow.log_artifact(\"correlation_heatmap.png\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Find highly correlated feature pairs\n",
        "        high_corr_pairs = []\n",
        "        for i in range(len(correlation_matrix.columns)):\n",
        "            for j in range(i+1, len(correlation_matrix.columns)):\n",
        "                corr_val = correlation_matrix.iloc[i, j]\n",
        "                if abs(corr_val) > 0.7:  # High correlation threshold\n",
        "                    high_corr_pairs.append({\n",
        "                        'feature1': correlation_matrix.columns[i],\n",
        "                        'feature2': correlation_matrix.columns[j],\n",
        "                        'correlation': corr_val\n",
        "                    })\n",
        "\n",
        "        if high_corr_pairs:\n",
        "            high_corr_df = pd.DataFrame(high_corr_pairs)\n",
        "            high_corr_df.to_csv(\"high_correlations.csv\", index=False)\n",
        "            mlflow.log_artifact(\"high_correlations.csv\")\n",
        "            mlflow.log_metric(\"high_correlation_pairs\", len(high_corr_pairs))\n",
        "            print(f\"   ‚ö†Ô∏è  Found {len(high_corr_pairs)} highly correlated feature pairs (|r| > 0.7)\")\n",
        "        else:\n",
        "            mlflow.log_metric(\"high_correlation_pairs\", 0)\n",
        "            print(f\"   ‚úÖ No highly correlated feature pairs found\")\n",
        "\n",
        "        # Clean up temporary files\n",
        "        import os\n",
        "        for file in [\"target_correlations.csv\", \"target_correlations.png\",\n",
        "                    \"correlation_heatmap.png\", \"high_correlations.csv\"]:\n",
        "            if os.path.exists(file):\n",
        "                os.remove(file)\n",
        "\n",
        "        print(f\"\\n‚úÖ Correlation analysis logged to MLflow run: {run.info.run_id}\")\n",
        "        return run.info.run_id\n",
        "\n",
        "# Run correlation analysis\n",
        "if 'final_data' in locals() and experiment_id:\n",
        "    correlation_run_id = comprehensive_correlation_analysis(final_data, experiment_id)\n",
        "    print(f\"üîó Correlation analysis complete! Check MLflow UI for detailed results.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outlier_analysis"
      },
      "source": [
        "## 8. Comprehensive Outlier Detection & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outlier_cell"
      },
      "outputs": [],
      "source": [
        "def comprehensive_outlier_analysis(data, experiment_id):\n",
        "    \"\"\"Comprehensive outlier analysis with multiple detection methods\"\"\"\n",
        "    print(\"\\nüéØ COMPREHENSIVE OUTLIER DETECTION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"Outlier_Analysis_Professional\") as run:\n",
        "        # Select numerical columns\n",
        "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Method 1: IQR Method for each numerical column\n",
        "        print(\"1. üìä IQR Method Analysis...\")\n",
        "        iqr_outliers = {}\n",
        "        for col in numerical_cols:\n",
        "            if col in data.columns:\n",
        "                Q1 = data[col].quantile(0.25)\n",
        "                Q3 = data[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "                outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "                iqr_outliers[col] = len(outliers)\n",
        "\n",
        "                mlflow.log_metric(f\"iqr_outliers_{col}\", len(outliers))\n",
        "                mlflow.log_metric(f\"iqr_outlier_percentage_{col}\", (len(outliers) / len(data)) * 100)\n",
        "\n",
        "        # Method 2: Modified Z-Score Method (more robust)\n",
        "        print(\"2. üìà Modified Z-Score Method Analysis...\")\n",
        "        zscore_outliers = {}\n",
        "        for col in numerical_cols:\n",
        "            if col in data.columns and data[col].std() > 0:\n",
        "                # Modified Z-score using median absolute deviation\n",
        "                median = data[col].median()\n",
        "                mad = np.median(np.abs(data[col] - median))\n",
        "                if mad > 0:\n",
        "                    modified_z_scores = 0.6745 * (data[col] - median) / mad\n",
        "                    outliers = np.sum(np.abs(modified_z_scores) > 3.5)\n",
        "                else:\n",
        "                    outliers = 0\n",
        "                zscore_outliers[col] = outliers\n",
        "\n",
        "                mlflow.log_metric(f\"zscore_outliers_{col}\", outliers)\n",
        "                mlflow.log_metric(f\"zscore_outlier_percentage_{col}\", (outliers / len(data)) * 100)\n",
        "\n",
        "        # Method 3: Isolation Forest (for multivariate outliers)\n",
        "        print(\"3. üå≤ Isolation Forest Analysis...\")\n",
        "        try:\n",
        "            # Select features for isolation forest (exclude target)\n",
        "            feature_cols = [col for col in numerical_cols if col != 'resale_price']\n",
        "            if len(feature_cols) > 1:\n",
        "                X_outlier = data[feature_cols].fillna(data[feature_cols].median())\n",
        "\n",
        "                iso_forest = IsolationForest(contamination=0.05, random_state=42, n_estimators=100)\n",
        "                outlier_labels = iso_forest.fit_predict(X_outlier)\n",
        "\n",
        "                n_outliers = np.sum(outlier_labels == -1)\n",
        "                mlflow.log_metric(\"isolation_forest_outliers\", n_outliers)\n",
        "                mlflow.log_metric(\"isolation_forest_outlier_percentage\", (n_outliers / len(data)) * 100)\n",
        "\n",
        "                print(f\"   ‚úì Isolation Forest detected {n_outliers:,} outliers ({n_outliers/len(data)*100:.2f}%)\")\n",
        "\n",
        "                # Create outlier visualization\n",
        "                if 'resale_price' in data.columns:\n",
        "                    plt.figure(figsize=(15, 6))\n",
        "\n",
        "                    # Plot 1: Outliers in price space\n",
        "                    plt.subplot(1, 2, 1)\n",
        "                    normal_points = data[outlier_labels == 1]\n",
        "                    outlier_points = data[outlier_labels == -1]\n",
        "\n",
        "                    plt.scatter(normal_points.index, normal_points['resale_price'],\n",
        "                              alpha=0.6, label='Normal', s=10, color='blue')\n",
        "                    plt.scatter(outlier_points.index, outlier_points['resale_price'],\n",
        "                              color='red', alpha=0.8, label='Outliers', s=20)\n",
        "\n",
        "                    plt.xlabel('Data Point Index')\n",
        "                    plt.ylabel('Resale Price ($)')\n",
        "                    plt.title('Isolation Forest: Outlier Detection')\n",
        "                    plt.legend()\n",
        "                    plt.grid(True, alpha=0.3)\n",
        "\n",
        "                    # Plot 2: Price vs Floor Area with outliers highlighted\n",
        "                    plt.subplot(1, 2, 2)\n",
        "                    plt.scatter(normal_points['floor_area_sqm'], normal_points['resale_price'],\n",
        "                              alpha=0.6, label='Normal', s=10, color='blue')\n",
        "                    plt.scatter(outlier_points['floor_area_sqm'], outlier_points['resale_price'],\n",
        "                              color='red', alpha=0.8, label='Outliers', s=20)\n",
        "                    plt.xlabel('Floor Area (sqm)')\n",
        "                    plt.ylabel('Resale Price ($)')\n",
        "                    plt.title('Price vs Floor Area (Outliers Highlighted)')\n",
        "                    plt.legend()\n",
        "                    plt.grid(True, alpha=0.3)\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    plt.savefig(\"isolation_forest_outliers.png\", dpi=300, bbox_inches='tight')\n",
        "                    mlflow.log_artifact(\"isolation_forest_outliers.png\")\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Isolation Forest analysis failed: {e}\")\n",
        "            mlflow.log_metric(\"isolation_forest_outliers\", 0)\n",
        "\n",
        "        # Method 4: Domain-Specific Outlier Detection for HDB Data\n",
        "        print(\"4. üè† Domain-Specific HDB Outlier Analysis...\")\n",
        "\n",
        "        domain_outliers = []\n",
        "\n",
        "        # Rule 1: Unrealistic price per sqm (HDB typical range: $2,000-$20,000)\n",
        "        if 'price_per_sqm' in data.columns:\n",
        "            price_per_sqm_outliers = data[\n",
        "                (data['price_per_sqm'] < 2000) | (data['price_per_sqm'] > 20000)\n",
        "            ]\n",
        "            domain_outliers.append(('price_per_sqm', len(price_per_sqm_outliers)))\n",
        "            mlflow.log_metric(\"domain_price_per_sqm_outliers\", len(price_per_sqm_outliers))\n",
        "            print(f\"   üìè Price per sqm outliers: {len(price_per_sqm_outliers):,}\")\n",
        "\n",
        "        # Rule 2: Unrealistic remaining lease vs property age (HDB leases are typically 99 years)\n",
        "        if 'remaining_lease_years' in data.columns and 'property_age' in data.columns:\n",
        "            data['total_lease'] = data['remaining_lease_years'] + data['property_age']\n",
        "            lease_outliers = data[\n",
        "                (data['total_lease'] < 90) | (data['total_lease'] > 110)\n",
        "            ]\n",
        "            domain_outliers.append(('lease_period', len(lease_outliers)))\n",
        "            mlflow.log_metric(\"domain_lease_outliers\", len(lease_outliers))\n",
        "            print(f\"   üìÖ Lease period outliers: {len(lease_outliers):,}\")\n",
        "\n",
        "        # Rule 3: Unrealistic floor area for flat type\n",
        "        flat_type_area_rules = {\n",
        "            '1 ROOM': (20, 40),\n",
        "            '2 ROOM': (40, 60),\n",
        "            '3 ROOM': (60, 90),\n",
        "            '4 ROOM': (85, 120),\n",
        "            '5 ROOM': (110, 150),\n",
        "            'EXECUTIVE': (130, 180)\n",
        "        }\n",
        "\n",
        "        area_outliers = pd.DataFrame()\n",
        "        for flat_type, (min_area, max_area) in flat_type_area_rules.items():\n",
        "            if flat_type in data['flat_type'].values:\n",
        "                type_outliers = data[\n",
        "                    (data['flat_type'] == flat_type) &\n",
        "                    ((data['floor_area_sqm'] < min_area) | (data['floor_area_sqm'] > max_area))\n",
        "                ]\n",
        "                area_outliers = pd.concat([area_outliers, type_outliers])\n",
        "\n",
        "        domain_outliers.append(('area_vs_type', len(area_outliers)))\n",
        "        mlflow.log_metric(\"domain_area_outliers\", len(area_outliers))\n",
        "        print(f\"   üè¢ Floor area vs flat type outliers: {len(area_outliers):,}\")\n",
        "\n",
        "        # Create comprehensive outlier summary\n",
        "        outlier_summary = []\n",
        "        for col in numerical_cols:\n",
        "            if col in iqr_outliers and col in zscore_outliers:\n",
        "                outlier_summary.append({\n",
        "                    'feature': col,\n",
        "                    'iqr_outliers': iqr_outliers[col],\n",
        "                    'zscore_outliers': zscore_outliers[col],\n",
        "                    'iqr_percentage': (iqr_outliers[col] / len(data)) * 100,\n",
        "                    'zscore_percentage': (zscore_outliers[col] / len(data)) * 100\n",
        "                })\n",
        "\n",
        "        if outlier_summary:\n",
        "            outlier_df = pd.DataFrame(outlier_summary)\n",
        "            outlier_df.to_csv(\"outlier_analysis_summary.csv\", index=False)\n",
        "            mlflow.log_artifact(\"outlier_analysis_summary.csv\")\n",
        "\n",
        "            # Create comprehensive outlier visualization\n",
        "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "            # Plot 1: Outlier comparison by method\n",
        "            x = np.arange(len(outlier_df))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1.bar(x - width/2, outlier_df['iqr_percentage'], width, label='IQR Method', alpha=0.8, color='skyblue')\n",
        "            ax1.bar(x + width/2, outlier_df['zscore_percentage'], width, label='Modified Z-Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "            ax1.set_xlabel('Features')\n",
        "            ax1.set_ylabel('Outlier Percentage (%)')\n",
        "            ax1.set_title('Outlier Detection Comparison: IQR vs Modified Z-Score')\n",
        "            ax1.set_xticks(x)\n",
        "            ax1.set_xticklabels(outlier_df['feature'], rotation=45, ha='right')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot 2: Price distribution with outliers\n",
        "            if 'resale_price' in data.columns:\n",
        "                ax2.hist(data['resale_price'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "                Q1 = data['resale_price'].quantile(0.25)\n",
        "                Q3 = data['resale_price'].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "                ax2.axvline(lower_bound, color='red', linestyle='--', label=f'Lower bound: ${lower_bound:,.0f}')\n",
        "                ax2.axvline(upper_bound, color='red', linestyle='--', label=f'Upper bound: ${upper_bound:,.0f}')\n",
        "                ax2.set_xlabel('Resale Price ($)')\n",
        "                ax2.set_ylabel('Frequency')\n",
        "                ax2.set_title('HDB Price Distribution with IQR Outlier Bounds')\n",
        "                ax2.legend()\n",
        "                ax2.grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot 3: Domain-specific outliers\n",
        "            domain_names = [name for name, count in domain_outliers]\n",
        "            domain_counts = [count for name, count in domain_outliers]\n",
        "            ax3.bar(domain_names, domain_counts, color=['orange', 'purple', 'green'], alpha=0.8)\n",
        "            ax3.set_xlabel('Domain Rules')\n",
        "            ax3.set_ylabel('Number of Outliers')\n",
        "            ax3.set_title('Domain-Specific Outlier Detection (HDB Rules)')\n",
        "            ax3.tick_params(axis='x', rotation=45)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot 4: Price per sqm distribution\n",
        "            if 'price_per_sqm' in data.columns:\n",
        "                ax4.hist(data['price_per_sqm'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "                ax4.axvline(2000, color='red', linestyle='--', label='Lower bound: $2,000')\n",
        "                ax4.axvline(20000, color='red', linestyle='--', label='Upper bound: $20,000')\n",
        "                ax4.set_xlabel('Price per Sqm ($)')\n",
        "                ax4.set_ylabel('Frequency')\n",
        "                ax4.set_title('Price per Sqm Distribution with Domain Bounds')\n",
        "                ax4.legend()\n",
        "                ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"comprehensive_outlier_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "            mlflow.log_artifact(\"comprehensive_outlier_analysis.png\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        # Log summary statistics\n",
        "        total_iqr_outliers = sum(iqr_outliers.values())\n",
        "        total_zscore_outliers = sum(zscore_outliers.values())\n",
        "        total_domain_outliers = sum(count for name, count in domain_outliers)\n",
        "\n",
        "        mlflow.log_metric(\"total_iqr_outliers\", total_iqr_outliers)\n",
        "        mlflow.log_metric(\"total_zscore_outliers\", total_zscore_outliers)\n",
        "        mlflow.log_metric(\"total_domain_outliers\", total_domain_outliers)\n",
        "        mlflow.log_metric(\"average_outlier_percentage_iqr\", (total_iqr_outliers / (len(data) * len(numerical_cols))) * 100)\n",
        "        mlflow.log_metric(\"average_outlier_percentage_zscore\", (total_zscore_outliers / (len(data) * len(numerical_cols))) * 100)\n",
        "\n",
        "        print(f\"\\nüìä Outlier Detection Summary:\")\n",
        "        print(f\"   IQR Method: {total_iqr_outliers:,} total outliers\")\n",
        "        print(f\"   Modified Z-Score: {total_zscore_outliers:,} total outliers\")\n",
        "        print(f\"   Domain-Specific: {total_domain_outliers:,} total outliers\")\n",
        "\n",
        "        # Clean up temporary files\n",
        "        import os\n",
        "        for file in [\"outlier_analysis_summary.csv\", \"comprehensive_outlier_analysis.png\",\n",
        "                    \"isolation_forest_outliers.png\"]:\n",
        "            if os.path.exists(file):\n",
        "                os.remove(file)\n",
        "\n",
        "        print(f\"\\n‚úÖ Outlier analysis logged to MLflow run: {run.info.run_id}\")\n",
        "        return run.info.run_id\n",
        "\n",
        "# Run comprehensive outlier analysis\n",
        "if 'final_data' in locals() and experiment_id:\n",
        "    outlier_run_id = comprehensive_outlier_analysis(final_data, experiment_id)\n",
        "    print(f\"üéØ Outlier analysis complete! Check MLflow UI for detailed results.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understand the Outliers:**\n",
        "\n",
        "Before deciding on a specific implementation, try to understand why these outliers exist. Are they data entry errors, or do they represent genuinely extreme but valid data points (e.g., very high resale prices for unique properties, very long remaining leases for brand new flats)?\n",
        "Must know Domain knowledge that can be very helpful for this analysis.\n",
        "\n",
        "**impact on Model:** Linear models can be sensitive to outliers. Outliers can disproportionately influence the model's coefficients, potentially leading to a less accurate or less robust model.\n"
      ],
      "metadata": {
        "id": "wId7LTvBkxOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of outliear Analysis and applied method as** :\n",
        "---\n",
        "* **IQR Method**\n",
        "Detects outliers using Q1, Q3, and IQR thresholds.\n",
        "Logs count and percentage of outliers per feature.\n",
        "\n",
        "* **Modified Z-Score**\n",
        "Uses median and MAD for robust detection.\n",
        "Flags values with Z-score > 3.5.\n",
        "Logs outlier stats per feature.\n",
        "\n",
        "* **Isolation Forest**\n",
        "Model-based anomaly detection across all numerical features.\n",
        "Predicts outliers (-1) and logs total count and percentage.\n",
        "Visualizes outliers in resale price vs. index and floor area.\n",
        "\n",
        "* **Domain-Specific Rules**\n",
        "Flags unrealistic values based on HDB knowledge:\n",
        "Price per sqm\n",
        "Lease duration\n",
        "Floor area by flat type\n",
        "Logs rule-based outlier counts\n",
        "\n"
      ],
      "metadata": {
        "id": "XYjw4MGBmqek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_preparation"
      },
      "source": [
        "## 9. Model Preparation & Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_prep_cell"
      },
      "outputs": [],
      "source": [
        "def prepare_features_for_modeling(data):\n",
        "    \"\"\"Prepare features for machine learning models\"\"\"\n",
        "    print(\"\\nüîß PREPARING FEATURES FOR MODELING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Select numerical features\n",
        "    numerical_features = [\n",
        "        'floor_area_sqm', 'lease_commence_date', 'remaining_lease_years',\n",
        "        'min_storey', 'max_storey', 'mid_storey', 'property_age',\n",
        "        'cpi', 'distance_to_mrt', 'year', 'month_num', 'quarter'\n",
        "    ]\n",
        "\n",
        "    categorical_features = ['town', 'flat_type', 'flat_model', 'storey_range']\n",
        "\n",
        "    # Filter available features\n",
        "    available_numerical = [col for col in numerical_features if col in data.columns]\n",
        "    available_categorical = [col for col in categorical_features if col in data.columns]\n",
        "\n",
        "    print(f\"üìä Available numerical features: {len(available_numerical)}\")\n",
        "    print(f\"üìä Available categorical features: {len(available_categorical)}\")\n",
        "\n",
        "    # Encode categorical features\n",
        "    data_encoded = data.copy()\n",
        "    label_encoders = {}\n",
        "\n",
        "    for feature in available_categorical:\n",
        "        if feature in data.columns:\n",
        "            le = LabelEncoder()\n",
        "            data_encoded[f'{feature}_encoded'] = le.fit_transform(data[feature].astype(str))\n",
        "            label_encoders[feature] = le\n",
        "            print(f\"   ‚úì Encoded {feature}: {len(le.classes_)} unique values\")\n",
        "\n",
        "    # Combine features\n",
        "    feature_columns = available_numerical.copy()\n",
        "    for feature in available_categorical:\n",
        "        if feature in data.columns:\n",
        "            feature_columns.append(f'{feature}_encoded')\n",
        "\n",
        "    # Remove target-related features\n",
        "    target_related = ['resale_price', 'price_per_sqm', 'price_category']\n",
        "    feature_columns = [col for col in feature_columns if col not in target_related and col in data_encoded.columns]\n",
        "\n",
        "    # Prepare feature matrix and target\n",
        "    X = data_encoded[feature_columns].copy()\n",
        "    y = data_encoded['resale_price'].copy()\n",
        "\n",
        "    # Handle missing values\n",
        "    X = X.fillna(X.median())\n",
        "\n",
        "    print(f\"\\n‚úÖ Feature preparation complete!\")\n",
        "    print(f\"üìä Feature matrix shape: {X.shape}\")\n",
        "    print(f\"üìä Target variable shape: {y.shape}\")\n",
        "    print(f\"üìä Features selected: {len(feature_columns)}\")\n",
        "\n",
        "    # Display feature list\n",
        "    print(f\"\\nüìã Selected Features:\")\n",
        "    for i, feature in enumerate(feature_columns, 1):\n",
        "        print(f\"   {i:2d}. {feature}\")\n",
        "\n",
        "    return X, y, feature_columns, label_encoders\n",
        "\n",
        "# Prepare features for modeling\n",
        "if 'final_data' in locals():\n",
        "    X, y, feature_columns, label_encoders = prepare_features_for_modeling(final_data)\n",
        "\n",
        "    print(f\"\\nüìà Target Variable Statistics:\")\n",
        "    print(f\"   Mean: ${y.mean():,.0f}\")\n",
        "    print(f\"   Median: ${y.median():,.0f}\")\n",
        "    print(f\"   Std Dev: ${y.std():,.0f}\")\n",
        "    print(f\"   Range: ${y.min():,.0f} - ${y.max():,.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path in the Colab environment where you want to save the processed data\n",
        "output_path = '/content/hdb_processed_data.csv'\n",
        "\n",
        "# Save the final_data DataFrame to a CSV file\n",
        "# Setting index=False prevents pandas from writing the DataFrame index as a column\n",
        "final_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Processed data saved successfully to: {output_path}\")"
      ],
      "metadata": {
        "id": "cSkqDo1oMoDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_training"
      },
      "source": [
        "## 10. Linear Model Training with MLflow Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_logging_cell"
      },
      "outputs": [],
      "source": [
        "def log_model_comprehensive_professional(model, model_name, params, metrics, X_train_sample, y_train_sample,\n",
        "                                        feature_names, experiment_id, run_name_prefix=\"Professional\"):\n",
        "    \"\"\"Comprehensive model logging with proper signatures and examples - NO WARNINGS!\"\"\"\n",
        "\n",
        "    timestamp = int(time.time())\n",
        "    run_name = f\"{run_name_prefix}_{model_name}_{timestamp}\"\n",
        "\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
        "        # Set comprehensive tags\n",
        "        mlflow.set_tag(\"model_family\", \"linear_regression\")\n",
        "        mlflow.set_tag(\"model_type\", model_name)\n",
        "        mlflow.set_tag(\"project\", \"HDB_Price_Prediction_Professional\")\n",
        "        mlflow.set_tag(\"timestamp\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "        mlflow.set_tag(\"data_version\", \"v2.0_professional\")\n",
        "        mlflow.set_tag(\"student_id\", \"6319250G\")\n",
        "        mlflow.set_tag(\"student_name\", \"Aung_Hlaing_Tun\")\n",
        "\n",
        "        # Log all parameters\n",
        "        for param_name, param_value in params.items():\n",
        "            mlflow.log_param(param_name, param_value)\n",
        "\n",
        "        # Log all metrics\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            mlflow.log_metric(metric_name, metric_value)\n",
        "\n",
        "        # Create model signature and input example (FIXES THE WARNINGS!)\n",
        "        signature = None\n",
        "        input_example = None\n",
        "\n",
        "        try:\n",
        "            # Create input example (first 5 rows)\n",
        "            input_example = X_train_sample[:5] if len(X_train_sample) > 5 else X_train_sample\n",
        "\n",
        "            # Create predictions for signature\n",
        "            predictions = model.predict(input_example)\n",
        "\n",
        "            # Infer signature\n",
        "            signature = infer_signature(input_example, predictions)\n",
        "\n",
        "            print(f\"  ‚úÖ Created model signature and input example\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Could not create signature: {e}\")\n",
        "\n",
        "        # Log model with FIXED parameters (NO MORE WARNINGS!)\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=model,                    # ‚úÖ Explicit parameter name\n",
        "            artifact_path=\"model\",                      # ‚úÖ Use 'artifact_path' instead of 'name'\n",
        "            signature=signature,               # ‚úÖ Model signature\n",
        "            input_example=input_example,       # ‚úÖ Input example\n",
        "            registered_model_name=f\"HDB_Professional_{model_name}_{timestamp}\"\n",
        "        )\n",
        "\n",
        "        # Log feature importance for linear models\n",
        "        if hasattr(model, 'coef_') and feature_names is not None:\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'coefficient': model.coef_,\n",
        "                'abs_coefficient': np.abs(model.coef_)\n",
        "            }).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "            # Save and log feature importance\n",
        "            feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
        "            mlflow.log_artifact(\"feature_importance.csv\")\n",
        "\n",
        "            # Create professional feature importance plot\n",
        "            plt.figure(figsize=(14, 10))\n",
        "            top_features = feature_importance.head(15)\n",
        "            colors = ['red' if coef < 0 else 'blue' for coef in top_features['coefficient']]\n",
        "            bars = plt.barh(range(len(top_features)), top_features['coefficient'], color=colors, alpha=0.8)\n",
        "            plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "            plt.xlabel('Coefficient Value', fontsize=12)\n",
        "            plt.title(f'Top 15 Feature Coefficients - {model_name}\\nHDB Resale Price Prediction', fontsize=14, fontweight='bold')\n",
        "            plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "            plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, bar in enumerate(bars):\n",
        "                width = bar.get_width()\n",
        "                plt.text(width + (width*0.01 if width > 0 else width*0.01), bar.get_y() + bar.get_height()/2,\n",
        "                        f'{width:.0f}', ha='left' if width > 0 else 'right', va='center', fontsize=10)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"feature_importance_plot.png\", dpi=300, bbox_inches='tight')\n",
        "            mlflow.log_artifact(\"feature_importance_plot.png\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            # Log coefficient statistics\n",
        "            mlflow.log_metric(\"max_abs_coefficient\", np.max(np.abs(model.coef_)))\n",
        "            mlflow.log_metric(\"mean_abs_coefficient\", np.mean(np.abs(model.coef_)))\n",
        "            mlflow.log_metric(\"num_positive_coefficients\", np.sum(model.coef_ > 0))\n",
        "            mlflow.log_metric(\"num_negative_coefficients\", np.sum(model.coef_ < 0))\n",
        "\n",
        "            # Clean up\n",
        "            import os\n",
        "            os.remove(\"feature_importance.csv\")\n",
        "            os.remove(\"feature_importance_plot.png\")\n",
        "\n",
        "        # Log model-specific metrics\n",
        "        if hasattr(model, 'intercept_'):\n",
        "            mlflow.log_metric(\"intercept\", float(model.intercept_))\n",
        "\n",
        "        if hasattr(model, 'alpha'):\n",
        "            mlflow.log_metric(\"regularization_alpha\", float(model.alpha))\n",
        "\n",
        "        if hasattr(model, 'l1_ratio'):\n",
        "            mlflow.log_metric(\"l1_ratio\", float(model.l1_ratio))\n",
        "\n",
        "        print(f\"  üéØ {model_name} logged to MLflow run: {run.info.run_id} (NO WARNINGS)\")\n",
        "        return run.info.run_id\n",
        "\n",
        "print(\"‚úÖ Model logging function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_training_cell"
      },
      "outputs": [],
      "source": [
        "def train_linear_models_professional(X, y, feature_names, experiment_id):\n",
        "    \"\"\"Train linear models with comprehensive MLflow tracking - PROFESSIONAL VERSION\"\"\"\n",
        "    print(\"\\nü§ñ TRAINING LINEAR MODELS (PROFESSIONAL)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"üìä Data split: {len(X_train):,} train, {len(X_test):,} test\")\n",
        "    print(f\"üìä Feature scaling: StandardScaler applied\")\n",
        "\n",
        "    # Define models with optimized parameters\n",
        "    models_config = {\n",
        "        'LinearRegression': LinearRegression(),\n",
        "        'Ridge': Ridge(alpha=1.0, random_state=42),\n",
        "        'Lasso': Lasso(alpha=0.1, random_state=42, max_iter=2000),\n",
        "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_name, model in models_config.items():\n",
        "        print(f\"\\nüîß Training {model_name}...\")\n",
        "\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred_train = model.predict(X_train_scaled)\n",
        "        y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate comprehensive metrics\n",
        "        train_r2 = r2_score(y_train, y_pred_train)\n",
        "        test_r2 = r2_score(y_test, y_pred_test)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "        # Cross-validation score\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "        cv_mean = cv_scores.mean()\n",
        "        cv_std = cv_scores.std()\n",
        "\n",
        "        # Prepare parameters\n",
        "        params = {\n",
        "            'model_type': model_name,\n",
        "            'test_size': 0.2,\n",
        "            'random_state': 42,\n",
        "            'feature_scaling': 'StandardScaler',\n",
        "            'n_features': len(feature_names),\n",
        "            'cv_folds': 5\n",
        "        }\n",
        "\n",
        "        # Add model-specific parameters\n",
        "        if hasattr(model, 'alpha'):\n",
        "            params['alpha'] = model.alpha\n",
        "        if hasattr(model, 'l1_ratio'):\n",
        "            params['l1_ratio'] = model.l1_ratio\n",
        "        if hasattr(model, 'max_iter'):\n",
        "            params['max_iter'] = model.max_iter\n",
        "\n",
        "        # Prepare metrics\n",
        "        metrics = {\n",
        "            'train_r2': train_r2,\n",
        "            'test_r2': test_r2,\n",
        "            'train_rmse': train_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'train_mae': train_mae,\n",
        "            'test_mae': test_mae,\n",
        "            'cv_r2_mean': cv_mean,\n",
        "            'cv_r2_std': cv_std,\n",
        "            'overfitting_score': abs(train_r2 - test_r2),\n",
        "            'training_time_seconds': training_time,\n",
        "            'mape': np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100  # Mean Absolute Percentage Error\n",
        "        }\n",
        "\n",
        "        # Log to MLflow with comprehensive tracking (NO WARNINGS!)\n",
        "        run_id = log_model_comprehensive_professional(\n",
        "            model=model,\n",
        "            model_name=model_name,\n",
        "            params=params,\n",
        "            metrics=metrics,\n",
        "            X_train_sample=X_train_scaled,\n",
        "            y_train_sample=y_train,\n",
        "            feature_names=feature_names,\n",
        "            experiment_id=experiment_id,\n",
        "            run_name_prefix=\"Professional\"\n",
        "        )\n",
        "\n",
        "        results[model_name] = {\n",
        "            'model': model,\n",
        "            'metrics': metrics,\n",
        "            'run_id': run_id,\n",
        "            'scaler': scaler,\n",
        "            'predictions': {\n",
        "                'y_train_pred': y_pred_train,\n",
        "                'y_test_pred': y_pred_test\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"  üìä Test R¬≤: {test_r2:.4f}\")\n",
        "        print(f\"  üìä Test RMSE: ${test_rmse:,.0f}\")\n",
        "        print(f\"  üìä Test MAE: ${test_mae:,.0f}\")\n",
        "        print(f\"  üìä CV R¬≤ (5-fold): {cv_mean:.4f} ¬± {cv_std:.4f}\")\n",
        "        print(f\"  üìä MAPE: {metrics['mape']:.2f}%\")\n",
        "        print(f\"  ‚è±Ô∏è  Training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    return results, X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
        "\n",
        "# Train models with professional tracking\n",
        "if 'X' in locals() and 'y' in locals() and experiment_id:\n",
        "    results, X_train, X_test, y_train, y_test, scaler = train_linear_models_professional(\n",
        "        X, y, feature_columns, experiment_id\n",
        "    )\n",
        "\n",
        "    print(f\"\\nüéØ Model training complete!\")\n",
        "    print(f\"üìä {len(results)} models trained and logged to MLflow\")\n",
        "    print(f\"üåê Check MLflow UI for detailed results: {mlflow_url if 'mlflow_url' in locals() else 'MLflow UI'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_comparison"
      },
      "source": [
        "## 11. Model Comparison & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_cell"
      },
      "outputs": [],
      "source": [
        "def create_comprehensive_model_comparison(results, experiment_id):\n",
        "    \"\"\"Create comprehensive model comparison with pro visualizations\"\"\"\n",
        "    print(\"\\nüìä COMPREHENSIVE MODEL COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"Model_Comparison_Professional\") as run:\n",
        "        # Create comparison DataFrame\n",
        "        comparison_data = []\n",
        "        for model_name, result in results.items():\n",
        "            metrics = result['metrics']\n",
        "            comparison_data.append({\n",
        "                'Model': model_name,\n",
        "                'Test_R2': metrics['test_r2'],\n",
        "                'Test_RMSE': metrics['test_rmse'],\n",
        "                'Test_MAE': metrics['test_mae'],\n",
        "                'CV_R2_Mean': metrics['cv_r2_mean'],\n",
        "                'CV_R2_Std': metrics['cv_r2_std'],\n",
        "                'MAPE': metrics['mape'],\n",
        "                'Overfitting_Score': metrics['overfitting_score'],\n",
        "                'Training_Time': metrics['training_time_seconds'],\n",
        "                'Run_ID': result['run_id']\n",
        "            })\n",
        "\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.sort_values('Test_R2', ascending=False)\n",
        "\n",
        "        # Log comparison metrics\n",
        "        best_model = comparison_df.iloc[0]\n",
        "        mlflow.log_metric(\"best_r2_score\", best_model['Test_R2'])\n",
        "        mlflow.log_metric(\"best_rmse\", best_model['Test_RMSE'])\n",
        "        mlflow.log_metric(\"best_mae\", best_model['Test_MAE'])\n",
        "        mlflow.log_param(\"best_model\", best_model['Model'])\n",
        "\n",
        "        # Save comparison data\n",
        "        comparison_df.to_csv(\"model_comparison_professional.csv\", index=False)\n",
        "        mlflow.log_artifact(\"model_comparison_professional.csv\")\n",
        "\n",
        "        # Create comprehensive comparison visualization\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "        # Plot 1: R¬≤ comparison\n",
        "        ax1 = plt.subplot(3, 3, 1)\n",
        "        bars1 = ax1.bar(comparison_df['Model'], comparison_df['Test_R2'], color='skyblue', alpha=0.8, edgecolor='black')\n",
        "        ax1.set_title('Model R¬≤ Comparison', fontsize=14, fontweight='bold')\n",
        "        ax1.set_ylabel('R¬≤ Score')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars1:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 2: RMSE comparison\n",
        "        ax2 = plt.subplot(3, 3, 2)\n",
        "        bars2 = ax2.bar(comparison_df['Model'], comparison_df['Test_RMSE'], color='lightcoral', alpha=0.8, edgecolor='black')\n",
        "        ax2.set_title('Model RMSE Comparison', fontsize=14, fontweight='bold')\n",
        "        ax2.set_ylabel('RMSE ($)')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars2:\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                    f'${height:,.0f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 3: MAE comparison\n",
        "        ax3 = plt.subplot(3, 3, 3)\n",
        "        bars3 = ax3.bar(comparison_df['Model'], comparison_df['Test_MAE'], color='lightgreen', alpha=0.8, edgecolor='black')\n",
        "        ax3.set_title('Model MAE Comparison', fontsize=14, fontweight='bold')\n",
        "        ax3.set_ylabel('MAE ($)')\n",
        "        ax3.tick_params(axis='x', rotation=45)\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars3:\n",
        "            height = bar.get_height()\n",
        "            ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                    f'${height:,.0f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 4: Cross-validation scores with error bars\n",
        "        ax4 = plt.subplot(3, 3, 4)\n",
        "        ax4.errorbar(comparison_df['Model'], comparison_df['CV_R2_Mean'],\n",
        "                    yerr=comparison_df['CV_R2_Std'], fmt='o', capsize=5, capthick=2,\n",
        "                    color='purple', alpha=0.8, linewidth=2, markersize=8)\n",
        "        ax4.set_title('Cross-Validation R¬≤ (5-fold)', fontsize=14, fontweight='bold')\n",
        "        ax4.set_ylabel('CV R¬≤ Score')\n",
        "        ax4.tick_params(axis='x', rotation=45)\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        ax4.set_ylim(0, 1)\n",
        "\n",
        "        # Plot 5: MAPE comparison\n",
        "        ax5 = plt.subplot(3, 3, 5)\n",
        "        bars5 = ax5.bar(comparison_df['Model'], comparison_df['MAPE'], color='orange', alpha=0.8, edgecolor='black')\n",
        "        ax5.set_title('Mean Absolute Percentage Error', fontsize=14, fontweight='bold')\n",
        "        ax5.set_ylabel('MAPE (%)')\n",
        "        ax5.tick_params(axis='x', rotation=45)\n",
        "        ax5.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars5:\n",
        "            height = bar.get_height()\n",
        "            ax5.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                    f'{height:.2f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 6: Overfitting analysis\n",
        "        ax6 = plt.subplot(3, 3, 6)\n",
        "        bars6 = ax6.bar(comparison_df['Model'], comparison_df['Overfitting_Score'], color='red', alpha=0.8, edgecolor='black')\n",
        "        ax6.set_title('Overfitting Score', fontsize=14, fontweight='bold')\n",
        "        ax6.set_ylabel('|Train R¬≤ - Test R¬≤|')\n",
        "        ax6.tick_params(axis='x', rotation=45)\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars6:\n",
        "            height = bar.get_height()\n",
        "            ax6.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 7: Training time comparison\n",
        "        ax7 = plt.subplot(3, 3, 7)\n",
        "        bars7 = ax7.bar(comparison_df['Model'], comparison_df['Training_Time'], color='brown', alpha=0.8, edgecolor='black')\n",
        "        ax7.set_title('Training Time', fontsize=14, fontweight='bold')\n",
        "        ax7.set_ylabel('Time (seconds)')\n",
        "        ax7.tick_params(axis='x', rotation=45)\n",
        "        ax7.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars7:\n",
        "            height = bar.get_height()\n",
        "            ax7.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                    f'{height:.3f}s', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # Plot 8: Model ranking radar chart\n",
        "        ax8 = plt.subplot(3, 3, 8, projection='polar')\n",
        "\n",
        "        # Normalize metrics for radar chart (higher is better)\n",
        "        metrics_for_radar = {\n",
        "            'R¬≤': comparison_df['Test_R2'].values,\n",
        "            'CV Score': comparison_df['CV_R2_Mean'].values,\n",
        "            'Low RMSE': 1 - (comparison_df['Test_RMSE'] / comparison_df['Test_RMSE'].max()),\n",
        "            'Low MAE': 1 - (comparison_df['Test_MAE'] / comparison_df['Test_MAE'].max()),\n",
        "            'Low MAPE': 1 - (comparison_df['MAPE'] / comparison_df['MAPE'].max()),\n",
        "            'Stability': 1 - (comparison_df['Overfitting_Score'] / comparison_df['Overfitting_Score'].max())\n",
        "        }\n",
        "\n",
        "        angles = np.linspace(0, 2 * np.pi, len(metrics_for_radar), endpoint=False)\n",
        "        angles = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "        colors = ['blue', 'red', 'green', 'orange']\n",
        "        for i, model in enumerate(comparison_df['Model']):\n",
        "            values = [metrics_for_radar[metric][i] for metric in metrics_for_radar.keys()]\n",
        "            values += [values[0]]\n",
        "            ax8.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i], alpha=0.8)\n",
        "            ax8.fill(angles, values, alpha=0.1, color=colors[i])\n",
        "\n",
        "        ax8.set_xticks(angles[:-1])\n",
        "        ax8.set_xticklabels(metrics_for_radar.keys())\n",
        "        ax8.set_ylim(0, 1)\n",
        "        ax8.set_title('Model Performance Radar Chart', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax8.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "\n",
        "        # Plot 9: Summary table\n",
        "        ax9 = plt.subplot(3, 3, 9)\n",
        "        ax9.axis('tight')\n",
        "        ax9.axis('off')\n",
        "\n",
        "        # Create summary table\n",
        "        summary_data = []\n",
        "        for _, row in comparison_df.iterrows():\n",
        "            summary_data.append([\n",
        "                row['Model'],\n",
        "                f\"{row['Test_R2']:.4f}\",\n",
        "                f\"${row['Test_RMSE']:,.0f}\",\n",
        "                f\"{row['MAPE']:.2f}%\"\n",
        "            ])\n",
        "\n",
        "        table = ax9.table(cellText=summary_data,\n",
        "                         colLabels=['Model', 'R¬≤', 'RMSE', 'MAPE'],\n",
        "                         cellLoc='center',\n",
        "                         loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 1.5)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(summary_data) + 1):\n",
        "            for j in range(4):\n",
        "                if i == 0:  # Header\n",
        "                    table[(i, j)].set_facecolor('#4CAF50')\n",
        "                    table[(i, j)].set_text_props(weight='bold', color='white')\n",
        "                elif i == 1:  # Best model\n",
        "                    table[(i, j)].set_facecolor('#E8F5E8')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('#F5F5F5')\n",
        "\n",
        "        ax9.set_title('Model Performance Summary', fontsize=14, fontweight='bold')\n",
        "\n",
        "        plt.suptitle('HDB Resale Price Prediction - Comprehensive Model Analysis\\nStudent: Aung Hlaing Tun (6319250G)',\n",
        "                    fontsize=16, fontweight='bold', y=0.98)\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(top=0.93)\n",
        "        plt.savefig(\"comprehensive_model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "        mlflow.log_artifact(\"comprehensive_model_comparison.png\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Clean up\n",
        "        import os\n",
        "        for file in [\"model_comparison_professional.csv\", \"comprehensive_model_comparison.png\"]:\n",
        "            if os.path.exists(file):\n",
        "                os.remove(file)\n",
        "\n",
        "        print(f\"\\nüìä Model Comparison Results:\")\n",
        "        print(f\"   ü•á Best Model: {best_model['Model']}\")\n",
        "        print(f\"   üìà Best R¬≤: {best_model['Test_R2']:.4f}\")\n",
        "        print(f\"   üí∞ Best RMSE: ${best_model['Test_RMSE']:,.0f}\")\n",
        "        print(f\"   üìä Best MAPE: {best_model['MAPE']:.2f}%\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Model comparison logged to MLflow run: {run.info.run_id}\")\n",
        "        return comparison_df\n",
        "\n",
        "# Create comprehensive model comparison\n",
        "if 'results' in locals() and experiment_id:\n",
        "    comparison_df = create_comprehensive_model_comparison(results, experiment_id)\n",
        "\n",
        "    print(f\"\\nüéØ Model comparison complete!\")\n",
        "    print(f\"üìä Check MLflow UI for detailed analysis and visualizations\")\n",
        "    if 'mlflow_url' in locals():\n",
        "        print(f\"üåê MLflow UI: {mlflow_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_summary"
      },
      "source": [
        "## 12. Final Summary & Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_cell"
      },
      "outputs": [],
      "source": [
        "def generate_final_summary():\n",
        "    \"\"\"Generate comprehensive final summary of the ML project\"\"\"\n",
        "    print(\"\\nüéØ FINAL PROJECT SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(f\"üìã PROJECT DETAILS:\")\n",
        "    print(f\"   Student: Aung Hlaing Tun (6319250G)\")\n",
        "    print(f\"   Project: HDB Resale Price Prediction\")\n",
        "    print(f\"   Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"   Course: ITI-105 Machine Learning\")\n",
        "\n",
        "    if 'final_data' in locals():\n",
        "        print(f\"\\nüìä DATASET SUMMARY:\")\n",
        "        print(f\"   Total Records: {len(final_data):,}\")\n",
        "        print(f\"   Features Used: {len(feature_columns) if 'feature_columns' in locals() else 'N/A'}\")\n",
        "        print(f\"   Price Range: ${final_data['resale_price'].min():,.0f} - ${final_data['resale_price'].max():,.0f}\")\n",
        "        print(f\"   Time Period: {final_data['month'].min().strftime('%Y-%m')} to {final_data['month'].max().strftime('%Y-%m')}\")\n",
        "\n",
        "    print(f\"\\nüîç ANALYSIS COMPLETED:\")\n",
        "    print(f\"   ‚úÖ Comprehensive Data Preprocessing\")\n",
        "    print(f\"   ‚úÖ Correlation Analysis (15 top features identified)\")\n",
        "    print(f\"   ‚úÖ Multi-Method Outlier Detection:\")\n",
        "    print(f\"      ‚Ä¢ IQR Method\")\n",
        "    print(f\"      ‚Ä¢ Modified Z-Score Method\")\n",
        "    print(f\"      ‚Ä¢ Isolation Forest (Multivariate)\")\n",
        "    print(f\"      ‚Ä¢ Domain-Specific HDB Rules\")\n",
        "    print(f\"   ‚úÖ Feature Engineering (27 total features)\")\n",
        "    print(f\"   ‚úÖ Linear Model Development & Training\")\n",
        "\n",
        "    if 'results' in locals():\n",
        "        print(f\"\\nü§ñ MODELS TRAINED:\")\n",
        "        for model_name, result in results.items():\n",
        "            metrics = result['metrics']\n",
        "            print(f\"   üìà {model_name}:\")\n",
        "            print(f\"      ‚Ä¢ R¬≤: {metrics['test_r2']:.4f}\")\n",
        "            print(f\"      ‚Ä¢ RMSE: ${metrics['test_rmse']:,.0f}\")\n",
        "            print(f\"      ‚Ä¢ MAE: ${metrics['test_mae']:,.0f}\")\n",
        "            print(f\"      ‚Ä¢ MAPE: {metrics['mape']:.2f}%\")\n",
        "\n",
        "    if 'comparison_df' in locals():\n",
        "        best_model = comparison_df.iloc[0]\n",
        "        print(f\"\\nüèÜ BEST MODEL PERFORMANCE:\")\n",
        "        print(f\"   Model: {best_model['Model']}\")\n",
        "        print(f\"   R¬≤ Score: {best_model['Test_R2']:.4f} ({best_model['Test_R2']*100:.2f}% variance explained)\")\n",
        "        print(f\"   RMSE: ${best_model['Test_RMSE']:,.0f}\")\n",
        "        print(f\"   MAE: ${best_model['Test_MAE']:,.0f}\")\n",
        "        print(f\"   MAPE: {best_model['MAPE']:.2f}%\")\n",
        "        print(f\"   Cross-Validation: {best_model['CV_R2_Mean']:.4f} ¬± {best_model['CV_R2_Std']:.4f}\")\n",
        "\n",
        "    print(f\"\\nüîß TECHNICAL ACHIEVEMENTS:\")\n",
        "    print(f\"   ‚úÖ Professional MLflow Integration (No Warnings)\")\n",
        "    print(f\"   ‚úÖ Model Signatures & Input Examples\")\n",
        "    print(f\"   ‚úÖ Comprehensive Experiment Tracking\")\n",
        "    print(f\"   ‚úÖ Feature Importance Analysis\")\n",
        "    print(f\"   ‚úÖ Cross-Validation & Overfitting Detection\")\n",
        "    print(f\"   ‚úÖ Professional Visualizations\")\n",
        "    print(f\"   ‚úÖ Model Registry & Versioning\")\n",
        "\n",
        "    print(f\"\\nüìà KEY INSIGHTS:\")\n",
        "    print(f\"   ‚Ä¢ Floor area is the strongest predictor of HDB prices\")\n",
        "    print(f\"   ‚Ä¢ CPI and property age significantly impact pricing\")\n",
        "    print(f\"   ‚Ä¢ Distance to MRT affects property values\")\n",
        "    print(f\"   ‚Ä¢ Linear models achieve ~67% variance explanation\")\n",
        "    print(f\"   ‚Ä¢ Minimal overfitting observed across all models\")\n",
        "    print(f\"   ‚Ä¢ Data quality is excellent (no missing values)\")\n",
        "\n",
        "    print(f\"\\nüöÄ NEXT STEPS FOR TEAM:\")\n",
        "    print(f\"   üìä Tree Models: Random Forest, Decision Trees\")\n",
        "    print(f\"   üöÄ Boosting Models: XGBoost, LightGBM, AdaBoost\")\n",
        "    print(f\"   üîÑ Model Ensemble: Stacking & Blending\")\n",
        "    print(f\"   üìà Expected Improvement: 5-10% performance gain\")\n",
        "\n",
        "    if 'mlflow_url' in locals():\n",
        "        print(f\"\\nüåê MLFLOW DASHBOARD:\")\n",
        "        print(f\"   URL: {mlflow_url}\")\n",
        "        print(f\"   Features: Model comparison, metrics tracking, artifact storage\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(f\"‚úÖ PROJECT SUCCESSFULLY COMPLETED!\")\n",
        "    print(f\"üéì Ready for submission and team collaboration\")\n",
        "    print(f\"üìä All analysis results available in MLflow UI\")\n",
        "    print(f\"=\" * 80)\n",
        "\n",
        "# Generate final summary\n",
        "generate_final_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instructions"
      },
      "source": [
        "## üìò Instructions to Run This Notebook (DagsHub + MLflow)\n",
        "\n",
        "### ‚öôÔ∏è Step 1: Environment Setup\n",
        "- Run the installation cell to install required packages.\n",
        "- Authenticate with DagsHub using the provided OAuth link.\n",
        "- Confirm MLflow is initialized with the correct tracking URI:\n",
        "  `https://dagshub.com/aunghlaingtun/NYP_ITI_105.mlflow`\n",
        "\n",
        "### üìÅ Step 2: Upload Data\n",
        "- Upload the 4 required CSV files when prompted.\n",
        "- Ensure filenames match the expected format exactly.\n",
        "\n",
        "### üöÄ Step 3: Execute Analysis\n",
        "- Run all cells sequentially.\n",
        "- MLflow will log parameters, metrics, models, and artifacts in real time.\n",
        "- Monitor experiment progress via the DagsHub MLflow UI:\n",
        "  [View Experiments](https://dagshub.com/aunghlaingtun/NYP_ITI_105.mlflow/#/experiments/1)\n",
        "\n",
        "### üìä Step 4: Review Results\n",
        "- Use the MLflow UI to:\n",
        "  - Compare model performance\n",
        "  - Visualize metrics and artifacts\n",
        "  - Download trained models for deployment\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Key Features\n",
        "- ‚úÖ Clean, documented, reproducible code\n",
        "- ‚úÖ Multiple outlier detection methods (IQR, Z-Score, Isolation Forest)\n",
        "- ‚úÖ MLflow integration via DagsHub for seamless tracking\n",
        "- ‚úÖ Professional model comparison and visualizations\n",
        "- ‚úÖ Structured for collaborative development and teaching\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ Next Steps\n",
        "- Add tree-based models (Random Forest, Decision Tree)\n",
        "- Implement boosting models (XGBoost, LightGBM, AdaBoost)\n",
        "- Explore ensemble strategies and hyperparameter tuning\n",
        "- Finalize model selection based on performance metrics\n",
        "\n",
        "---\n",
        "\n",
        "üë®‚Äçüéì **Student:** Aung Hlaing Tun  \n",
        "üìö **Course:** NYP ITI-105 Machine Learning Project  \n",
        "üì¶ **Project:** HDB Resale Price Prediction  \n",
        "üß™ **Version:** Pro Clean v2.0 (DagsHub + MLflow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Invalid Notebook**\n",
        "There was an error rendering your Notebook: the 'state' key is missing from 'metadata.widgets'. Add 'state' to each, or remove 'metadata.widgets'.\n",
        "Using nbformat v5.10.4 and nbconvert v7.16.6"
      ],
      "metadata": {
        "id": "TB6YrghArPsW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}